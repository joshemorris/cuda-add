// Josh Morris
// Lab 6
// Dr Pettey
// 4330 Parallel Processing

/*
A cuda program to add two 16X32 matrices supplied by the user
The host will print the result generated by the kernel
*/

#include <stdio.h>
#include <stdlib.h>

const int NUM_ROW = 16;
const int NUM_COL = 32;

__global__
void addMatrices(int arraySize, int* a, int* b) {
	// calculate position
	int i = blockIdx.x * blockDim.x + threadIdx.x;

	// if in array, add	
	if (i < arraySize) {
		a[i] += b[i];
	}
}


int main(){
	const int arraySize = NUM_ROW * NUM_COL; //total number of elements in each array
	int i, j; //counters
	int* a; // Host A
	int* b; // Host B
	int* d_a; // device A
	int* d_b; // device B

	// allocate matrix A
	a = (int*)malloc(sizeof(int) * arraySize);

	// allocate matrix B
	b = (int*)malloc(sizeof(int) * arraySize);

	//allocate A and B in the GPU
	cudaMalloc(&d_a, arraySize * sizeof(int));
	cudaMalloc(&d_b, arraySize * sizeof(int));

	// get matrix A
	printf("Please input matrix A:\n");

	for (i = 0; i < arraySize; ++i) {
		scanf("%i", &a[i]);
	}

	//get matrix B
	printf("Please input matrix B:\n");

	for (i = 0; i < arraySize; ++i) {
		scanf("%d", &b[i]);
	}	

	//copy data to the GPU
	cudaMemcpy(d_a, a, sizeof(int) * arraySize, cudaMemcpyHostToDevice);
	cudaMemcpy(d_b, b, sizeof(int) * arraySize, cudaMemcpyHostToDevice);

	//issue command to GPU
	addMatrices<<<(arraySize+511)/512, 512>>>(arraySize, d_a, d_b);

	//copy data from device a to host a
	cudaMemcpy(a, d_a, sizeof(int) * arraySize, cudaMemcpyDeviceToHost);

	//print the results
	for (i = 0; i < NUM_ROW; ++i){
		for(j = 0; j < NUM_COL; ++j) {
			printf("%d ", a[(i*NUM_COL) + j]);
		}
		printf("\n");
	}

	//clean up
	free(a);
	free(b);
	cudaFree(d_a);
	cudaFree(d_b);
}